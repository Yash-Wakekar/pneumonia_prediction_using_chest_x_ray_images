{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvI9_QNwGY4u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRnrow2EIgKQ",
        "outputId": "ef912893-631a-458d-e7f4-c01bc18f452b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 10,\n",
        "                                   zoom_range = 0.25,\n",
        "                                   horizontal_flip = True,\n",
        "                                   vertical_flip=True,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   rotation_range=20,\n",
        "                                   fill_mode = 'nearest')\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/ML_miniproject/archive (1)/chest_xray (1)/train (1)',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 color_mode=\"rgb\",\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/ML_miniproject/archive (1)/chest_xray (1)/test (1)',\n",
        "                                            target_size = (224, 224),\n",
        "                                            color_mode=\"rgb\",\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "val_set = test_datagen.flow_from_directory('/content/drive/MyDrive/ML_miniproject/archive (1)/chest_xray (1)/val (1)',\n",
        "                                            target_size=(224,224),\n",
        "                                           color_mode=\"rgb\",\n",
        "                                           batch_size = 2,\n",
        "                                           class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYRif6KgIh0j",
        "outputId": "da87856c-c853-4fe9-a0d1-7742ab168220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5219 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-hdDr4ZP8Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                  patience=10)"
      ],
      "metadata": {
        "id": "siWZmu9EI7Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                          patience=8)"
      ],
      "metadata": {
        "id": "AkHWfepjI71C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model3():\n",
        "  model3 = Sequential()\n",
        "\n",
        "  pretrained_model=tf.keras.applications.vgg16.VGG16(include_top=False,\n",
        "                    input_shape=(224,224,3),\n",
        "                    pooling='avg',classes=2,\n",
        "                    weights='imagenet')\n",
        "  for layer in pretrained_model.layers:\n",
        "          layer.trainable=False\n",
        "\n",
        "  model3.add(pretrained_model)\n",
        "  model3.add(Flatten())\n",
        "  model3.add(Dense(512, activation='relu'))\n",
        "  \n",
        "  model3.add(Dense(1, activation='sigmoid'))\n",
        "  model3.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "  return model3\n"
      ],
      "metadata": {
        "id": "9xN1PHxsK12Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_new = create_model3()"
      ],
      "metadata": {
        "id": "0MXr_55mP9tT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ee405f-16b9-4240-c907-a7c8cff8ef47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQ5kn4xCyPos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_new.fit(x = training_set, validation_data=val_set,steps_per_epoch=100,callbacks=[early_stopping,lr], epochs = 7,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D22yystzQlb9",
        "outputId": "b1b2d891-1e88-4979-8063-5e334399ff43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "100/100 [==============================] - 1796s 17s/step - loss: 0.3601 - accuracy: 0.8322 - val_loss: 0.5813 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 2/7\n",
            "100/100 [==============================] - 1695s 17s/step - loss: 0.2750 - accuracy: 0.8859 - val_loss: 0.4409 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 3/7\n",
            "100/100 [==============================] - 1710s 17s/step - loss: 0.2487 - accuracy: 0.8994 - val_loss: 0.4415 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 4/7\n",
            "100/100 [==============================] - 1697s 17s/step - loss: 0.2447 - accuracy: 0.8978 - val_loss: 0.4346 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 5/7\n",
            "100/100 [==============================] - 1723s 17s/step - loss: 0.2180 - accuracy: 0.9084 - val_loss: 0.5050 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 6/7\n",
            "100/100 [==============================] - 1696s 17s/step - loss: 0.2146 - accuracy: 0.9082 - val_loss: 0.4837 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 7/7\n",
            "100/100 [==============================] - 1694s 17s/step - loss: 0.2124 - accuracy: 0.9117 - val_loss: 0.4535 - val_accuracy: 0.7500 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1000fa9590>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "mc"
      ],
      "metadata": {
        "id": "qd_E3sHZntMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ce3e5c-cd7c-425b-9c6b-9ecd0385012f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.ModelCheckpoint at 0x7f0ffb1731d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_new.save('final_model_vgg_final.h5') "
      ],
      "metadata": {
        "id": "fpF-lw3BosJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from google.colab import files\n",
        "from keras.models import load_model\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "model=load_model('final_model_vgg_final.h5')"
      ],
      "metadata": {
        "id": "YMacYeEXJ1pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(training_set)\n",
        "\n",
        "print(\"Train Loss: \", score[0])\n",
        "print(\"Train Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(test_set)\n",
        "print(\"\\nTest loss: \", score[0])\n",
        "print(\"Test Accuracy: \", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpzA-FyEdrkN",
        "outputId": "cdec2167-c831-485c-f8d2-4c10af39c35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164/164 [==============================] - 2846s 17s/step - loss: 0.1908 - accuracy: 0.9268\n",
            "Train Loss:  0.1907568722963333\n",
            "Train Accuracy:  0.9268059134483337\n",
            "20/20 [==============================] - 337s 17s/step - loss: 0.2460 - accuracy: 0.9006\n",
            "\n",
            "Test loss:  0.24604423344135284\n",
            "Test Accuracy:  0.9006410241127014\n"
          ]
        }
      ]
    }
  ]
}